{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under construction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.constants import OUTPUT_DIR\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ---------------------------- Constants -----------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "# INFILE\n",
    "# OUTFILE\n",
    "# SPECIAL_TOKENS\n",
    "# UNK\n",
    "\n",
    "# READING_TO_GLYPH_NAME\n",
    "# GLYPH_NAME_TO_UNICODE\n",
    "# GLYPH_NAMES\n",
    "# GLYPH_NAME_TO_READINGS\n",
    "\n",
    "# NUMBERS_TO_MORPHEMES\n",
    "\n",
    "# SIGN_LIST_REPLACEMENTS\n",
    "# SIGN_NAME_REPLACEMENTS\n",
    "# READING_PLUS_SIGN_NAME_REPLACEMENTS\n",
    "# READING_REPLACEMENTS\n",
    "# NUM_REPLACEMENTS\n",
    "# FINAL_REPLACEMENTS\n",
    "# ALL_REPLACEMENTS\n",
    "\n",
    "INFILE = f\"{OUTPUT_DIR}/3_cleaned_transliterations.csv\"\n",
    "OUTFILE = f\"{OUTPUT_DIR}/5_with_glyphs.csv\"\n",
    "\n",
    "SPECIAL_TOKENS = {\n",
    "    \"<SURFACE>\",\n",
    "    \"<COLUMN>\",\n",
    "    \"<BLANK_SPACE>\",\n",
    "    \"<RULING>\",\n",
    "    \"...\",\n",
    "    \"\\n\",\n",
    "    \"<unk>\",\n",
    "}\n",
    "\n",
    "UNK = \"<unk>\"\n",
    "\n",
    "# reading (str) -> list of glyph names (list[str])\n",
    "with open(f\"{OUTPUT_DIR}/morpheme_to_glyph_names.json\", encoding=\"utf-8\") as infile:\n",
    "    READING_TO_GLYPH_NAME: dict[str, list[str]] = json.load(infile)\n",
    "\n",
    "# glyph name (str) -> unicode (str)\n",
    "with open(f\"{OUTPUT_DIR}/glyph_name_to_glyph.json\", encoding=\"utf-8\") as infile:\n",
    "    GLYPH_NAME_TO_UNICODE: dict[str, str] = json.load(infile)\n",
    "\n",
    "# set of all glyph names\n",
    "GLYPH_NAMES = set(GLYPH_NAME_TO_UNICODE.keys())\n",
    "\n",
    "# glyph name (str) -> readings (list[str])\n",
    "GLYPH_NAME_TO_READINGS: dict[str, list[str]] = defaultdict(list)\n",
    "for reading, glyph_names in READING_TO_GLYPH_NAME.items():\n",
    "    for glyph_name in glyph_names:\n",
    "        GLYPH_NAME_TO_READINGS[glyph_name].append(reading)\n",
    "for k, v in GLYPH_NAME_TO_READINGS.items():\n",
    "    GLYPH_NAME_TO_READINGS[k] = list(set(v))\n",
    "\n",
    "NUMBERS_TO_READINGS = {\n",
    "    \"1/2\": \"1/2(diš)\",\n",
    "    \"1/3\": \"1/3(diš)\",\n",
    "    \"1/4\": \"1/3(iku)\",\n",
    "    \"2/3\": \"2/3(diš)\",\n",
    "    \"5/6\": \"5/6(diš)\",\n",
    "    \"1\": \"1(diš)\",\n",
    "    \"2\": \"2(diš)\",\n",
    "    \"3\": \"3(diš)\",\n",
    "    \"4\": \"4(diš)\",\n",
    "    \"5\": \"5(diš)\",\n",
    "    \"6\": \"6(diš)\",\n",
    "    \"7\": \"7(diš)\",\n",
    "    \"8\": \"8(diš)\",\n",
    "    \"9\": \"9(diš)\",\n",
    "    \"10\": \"1(u)\",\n",
    "    \"11\": \"1(u) 1(diš)\",\n",
    "    \"12\": \"1(u) 2(diš)\",\n",
    "    \"14\": \"1(u) 4(diš)\",\n",
    "    \"18\": \"1(u) 8(diš)\",\n",
    "    \"20\": \"2(u)\",\n",
    "    \"21\": \"2(u) 1(diš)\",\n",
    "    \"23\": \"2(u) 3(diš)\",\n",
    "    \"24\": \"2(u) 4(diš)\",\n",
    "    \"25\": \"2(u) 5(diš)\",\n",
    "    \"30\": \"3(u)\",\n",
    "    \"36\": \"3(u) 6(diš)\",\n",
    "    \"40\": \"4(u)\",\n",
    "    \"50\": \"5(u)\",\n",
    "    \"60\": \"6(u)\",\n",
    "    \"600\": \"1(gešʾu)\",\n",
    "    \"900\": \"1(gešʾu) 5(geš₂)\",\n",
    "    \"3600\": \"1(šarʾu@c)\",\n",
    "    \"36000\": \"1(šar₂)\",\n",
    "}\n",
    "\n",
    "\n",
    "SIGN_LIST_REPLACEMENTS = {\n",
    "    \"BAU377\": \"GIŠ\",  # technically GIŠ~v...\n",
    "    \"KWU147\": \"LIL\",\n",
    "    \"KWU354\": \"LUM\",\n",
    "    \"KWU636\": \"KU₄\",\n",
    "    \"KWU777\": \"ŠITA\",\n",
    "    \"KWU844\": \"|E₂×AŠ@t|\",\n",
    "    \"LAK060\": \"|UŠ×TAK₄|\",\n",
    "    \"LAK085\": \"|SI×TAK₄|\",\n",
    "    \"LAK173\": \"KAD₅\",\n",
    "    \"LAK175\": \"SANGA₂\",\n",
    "    \"LAK218\": \"|ZU&ZU.SAR|\",\n",
    "    \"LAK449\": \"|NUNUZ.AB₂|\",\n",
    "    \"LAK524\": \"|ZUM×TUG₂|\",\n",
    "    \"LAK589\": \"GISAL\",\n",
    "    \"LAK672a\": \"UŠX\",\n",
    "    \"LAK672b\": \"MUNSUB\",\n",
    "    \"LAK720\": \"|LAK648×(PAP.PAP.LU₃)|\",\n",
    "    \"LAK769\": \"|LAGAB×AN|\",\n",
    "    \"LAK777\": \"|DAG.KISIM₅×UŠ|\",\n",
    "}\n",
    "\n",
    "GLYPH_NAME_REPLACEMENTS = {\n",
    "    \"(ŠE.1(AŠ))\": \"(ŠE.AŠ)\",\n",
    "    \"(ŠE.2(AŠ))\": \"(ŠE.AŠ.AŠ)\",\n",
    "    \"|E₂.BALAG|\": \"|KID.BALAG|\",\n",
    "    \"|SAHAR.DU₆.TAK₄|\": \"IŠ LAGAR@g TAK₄\",\n",
    "    \"|ŠE.ŠE|\": \"ŠE ŠE\",\n",
    "    \"(EN.ZU-TI.LA.BI-DU₁₁.GA)\": \"|EN.ZU| TI LA BI KA GA\",\n",
    "    \"|EN₂.E₂|\": \"|ŠU₂.AN| E₂\",\n",
    "    \"|TAB.BA|\": \"TAB BA\",\n",
    "    \"|GAR.UD|\": \"GAR UD\",\n",
    "    \"|NE.DAG|\": \"NE DAG\",\n",
    "    \"|ŠU₂.DUN₃@g@g@s|\": \"|ŠU₂.DUN₃|\",\n",
    "    \"BAD₃\": \"|EZEN×BAD|\",\n",
    "    \"BIL₂\": \"NE@s\",\n",
    "    \"DU₈\": \"DUH\",\n",
    "    \"ERIM\": \"ERIN₂\",\n",
    "    \"GAG\": \"KAK\",\n",
    "    \"GIN₂\": \"DUN₃@g\",\n",
    "    \"GU₄\": \"GUD\",\n",
    "    \"GUB\": \"DU\",\n",
    "    \"ITI\": \"|UD×(U.U.U)|\",\n",
    "    \"MUNUS\": \"SAL\",\n",
    "    \"NIG₂\": \"GAR\",\n",
    "    \"ŠAG₄\": \"ŠA₃\",\n",
    "    \"ŠE₃\": \"EŠ₂\",\n",
    "    \"SILA₄\": \"|GA₂×PA|\",\n",
    "    \"SIG₇\": \"IGI@g\",\n",
    "    \"TUR₃\": \"|NUN.LAGAR|\",\n",
    "    \"UH₃\": \"KUŠU₂\",\n",
    "    \"U₈\": \"|LAGAB×(GUD&GUD)|\",\n",
    "}\n",
    "\n",
    "# Remember that this comes after the above replacements,\n",
    "# so some of the parenthetical values have already been replaced\n",
    "READING_PLUS_SIGN_NAME_REPLACEMENTS = {\n",
    "    \"ad₆ \": \"ad₆(|LU₂.LAGAB×U|) \",\n",
    "    \"dabₓ(|LAGAB×(GUD&GUD)|)\": \"dibₓ(|LAGAB×(GUD&GUD)|)\",\n",
    "    \"erinₓ(KWU896)\": \"erenₓ(KWU896)\",\n",
    "    \"gurₓ(|ŠE.KIN|)še₃\": \"gurₓ(|ŠE.KIN|)-še₃\",\n",
    "    \"gurumₓ(|IGI.ERIN₂|)\": \"gurum₂\",\n",
    "    \"ilduₓ(NAGAR)\": \"nagar\",\n",
    "    \"itiₓ(|UD@s×BAD|)\": \"iti₂(|UD@s×BAD|)\",\n",
    "    \"itiₓ(|UD@s×TIL|)\": \"iti₂(|UD@s×BAD|)\",\n",
    "    \"kuₓ(KU₄)\": \"ku₄\",\n",
    "    \"lumₓ(LUM)\": \"lum\",\n",
    "    \"mudₓ(|NUNUZ.AB₂|)\": \"mud₃(|NUNUZ.AB₂|)\",\n",
    "    \"sangaₓ(|ŠID.GAR|)\": \"saŋŋaₓ(|ŠID.GAR|)\",\n",
    "    \"šaganₓ(AMA)\": \"daŋal\",\n",
    "    \"šitaₓ(ŠITA)\": \"šita\",\n",
    "    \"tabₓ(MAN)\": \"tab₄\",\n",
    "    \"umbinₓ(|UR₂×KID₂|)\": \"umbin(|UR₂×KID₂|)\",\n",
    "    \"ušurₓ(|LAL₂×TUG₂|)\": \"ušurₓ(|LAL₂.TUG₂|)\",\n",
    "    \"ugaₓ(NAGA)\": \"uga₃\",\n",
    "    \"zeₓ(SIG₇)\": \"ziₓ(IGI@g)\",\n",
    "    \"zeₓ(IGI@g)\": \"ziₓ(IGI@g)\",\n",
    "}\n",
    "\n",
    "READING_REPLACEMENTS = {\n",
    "    \"babila\": \"babilim\",\n",
    "    \"eri₁₃\": \"ere₁₃\",\n",
    "    \"eriš₂\": \"ereš₂\",\n",
    "    \"šu+nigin₂\": \"šuniŋin\",\n",
    "    \"šu+nigin\": \"šuniŋin\",\n",
    "    \"+...\": \"...\",\n",
    "    \"...+\": \"...\",\n",
    "    \"@c\": \"\",\n",
    "    \"@t\": \"\",\n",
    "    \"@v\": \"\",\n",
    "    \"@90\": \"\",\n",
    "}\n",
    "\n",
    "# As far as I can tell, there are at most 2 ways to do fractions\n",
    "NUM_REPLACEMENTS = {\n",
    "    \"1/2(aš)\": \"1/2\",\n",
    "    \"1/3(aš)\": \"1/3\",\n",
    "    \"1/4(aš)\": \"1/4\",\n",
    "    \"2/3(aš)\": \"2/3\",\n",
    "    \"5/6(aš)\": \"5/6\",\n",
    "}\n",
    "\n",
    "FINAL_REPLACEMENTS = {\n",
    "    \"||LAGAB×(GUD&GUD)|+HUL₂|\": \"|LAGAB×(GUD&GUD)+HUL₂|\",\n",
    "    \"||EZEN×BAD|.AN|\": \"|EZEN×BAD.AN|\",\n",
    "    \"|NINDA₂×(ŠE.2(AŠ@c))|\": \"|NINDA₂×(ŠE.AŠ.AŠ)|\",\n",
    "}\n",
    "\n",
    "ALL_REPLACEMENTS = [\n",
    "    SIGN_LIST_REPLACEMENTS,\n",
    "    GLYPH_NAME_REPLACEMENTS,\n",
    "    READING_PLUS_SIGN_NAME_REPLACEMENTS,\n",
    "    READING_REPLACEMENTS,\n",
    "    NUM_REPLACEMENTS,\n",
    "    FINAL_REPLACEMENTS,\n",
    "]\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ---------------------------- Globals  ------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "unk_readings_all = []\n",
    "non_unk_readings_all = []\n",
    "\n",
    "unk_readings_sign_name = []\n",
    "unk_readings_num = []\n",
    "unk_reading_other = []\n",
    "\n",
    "\n",
    "glyph_names_not_in_map = []\n",
    "glyph_names_no_unicode = []\n",
    "glyph_names_found_unicode = []\n",
    "\n",
    "glyph_to_observed_readings = {}\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ------------------------------- Main  ------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "def main():\n",
    "    df = pd.read_csv(INFILE).fillna(\"\")\n",
    "\n",
    "    # Drop \"transliteration\" column\n",
    "    df = df.drop(columns=[\"transliteration\"])\n",
    "\n",
    "    # Rename transliteration_clean to transliteration\n",
    "    df = df.rename(columns={\"transliteration_clean\": \"transliteration\"})\n",
    "\n",
    "    # Replace some of the glyph names already present in the transliteration\n",
    "    # (used when reading is uncertain) with more standard equivalents.\n",
    "    for replacements in ALL_REPLACEMENTS:\n",
    "        for k, v in replacements.items():\n",
    "            df[\"transliteration\"] = df[\"transliteration\"].str.replace(k, v, regex=False)\n",
    "\n",
    "    df = _add_glyphs(df)\n",
    "    _print_reading_to_glyph_name_stats()  # how successful?\n",
    "    _print_glyph_name_to_unicode_stats()  # how successful?\n",
    "\n",
    "    # (3) Postprocessing\n",
    "    df[\"transliteration\"] = df[\"transliteration\"].str.replace(\n",
    "        r\"\\ *\\n\\ *\", \"\\n\", regex=True\n",
    "    )\n",
    "    df[\"transliteration\"] = df[\"transliteration\"].str.replace(\"-{\", \"{\", regex=False)\n",
    "    df[\"transliteration\"] = df[\"transliteration\"].str.replace(\"}-\", \"}\", regex=False)\n",
    "    df[\"transliteration\"] = df[\"transliteration\"].str.replace(\n",
    "        \"<unk>-\", \"<unk> \", regex=False\n",
    "    )\n",
    "    df[\"transliteration\"] = df[\"transliteration\"].str.replace(\n",
    "        \"-<unk>\", \" <unk>\", regex=False\n",
    "    )\n",
    "\n",
    "    for key in [\"transliteration\", \"glyph_names\", \"glyphs\"]:\n",
    "        df[key] = df[key].str.replace(r\"(\\ *\\.{3,} *)+\", \"...\", regex=True)\n",
    "\n",
    "    df[\"glyphs\"] = df[\"glyphs\"].str.replace(\" \", \"\", regex=False)\n",
    "\n",
    "    # Reorganize rows\n",
    "    df = df[\n",
    "        [\n",
    "            \"id\",\n",
    "            \"period\",\n",
    "            \"genre\",\n",
    "            \"transliteration\",\n",
    "            \"glyph_names\",\n",
    "            \"glyphs\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    df = _drop_rows_with_identical_transliterations(df)\n",
    "    df = _drop_rows_with_identical_glyphs(df)\n",
    "\n",
    "    _print_glyph_count(df)\n",
    "    _write(df, separate_genre_files=True)\n",
    "    _save_glyph_to_observed_readings()\n",
    "\n",
    "\n",
    "def _add_glyphs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print()\n",
    "    print(\"Adding glyphs...\")\n",
    "    df = df.progress_apply(_add_glyphs_to_row, axis=1)\n",
    "    print(\"Done!\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def _add_glyphs_to_row(row: pd.Series) -> pd.Series:\n",
    "    text = row[\"transliteration\"]\n",
    "\n",
    "    # (1) Get it ready for tokenization\n",
    "    # --------------------------------\n",
    "    text = text.replace(\"\\n\", \" \\n \")\n",
    "    text = text.replace(\"...\", \" ... \")\n",
    "    text = re.sub(r\"\\ +\", \" \", text)\n",
    "\n",
    "    # (2) Split into wordforms (e.g. lugal-la-ka)\n",
    "    # --------------------------------\n",
    "    wordforms = [wf for wf in text.split(\" \") if wf and wf != \"|\" and wf != \".|\"]\n",
    "\n",
    "    # (3) Get glyph names\n",
    "    # --------------------------------\n",
    "    transliteration = \"\"\n",
    "    glyph_names = \"\"\n",
    "    glyphs = \"\"\n",
    "\n",
    "    for wordform in wordforms:\n",
    "        data = _get_wordform_glyph_data(wordform)  # [(morpheme, glyph_name, glyph), ]\n",
    "        transliteration += \"-\".join([morpheme for morpheme, _, _ in data]) + \" \"\n",
    "        glyph_names += \" \".join([glyph_name for _, glyph_name, _ in data]) + \" \"\n",
    "        glyphs += \"\".join([glyph for _, _, glyph in data]) + \" \"\n",
    "\n",
    "        # Record observed readings\n",
    "        for item in data:\n",
    "            morpheme, _, glyph = item\n",
    "            if morpheme in SPECIAL_TOKENS:\n",
    "                continue\n",
    "            # morpheme_ = morpheme.replace(\"{\", \"\").replace(\"}\", \"\")\n",
    "            if glyph not in glyph_to_observed_readings:\n",
    "                glyph_to_observed_readings[glyph] = Counter()\n",
    "            glyph_to_observed_readings[glyph][morpheme] += 1\n",
    "\n",
    "    row[\"transliteration\"] = transliteration.strip()\n",
    "    row[\"glyph_names\"] = glyph_names.strip()\n",
    "    row[\"glyphs\"] = glyphs.strip()\n",
    "    return row\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# --------------------------- Glyph Names  ---------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "SWAP_GLYPH_NAMES = {\n",
    "    \"UN\": \"KALAM@g\",\n",
    "    \"ŠITA₂\": \"|ŠITA.GIŠ|\",\n",
    "    \"DE₂\": \"|UMUM×KASKAL|\",\n",
    "    \"|ŠU₂.3xAN|\": \"|ŠU₂.3×AN|\",\n",
    "    \"|ŠU₂.DUN₃@g@g@s|\": \"|ŠU₂.DUN₃|\",\n",
    "    \"LAK212\": \"|A.TU.GABA.LIŠ|\",\n",
    "}\n",
    "\n",
    "\n",
    "def _get_wordform_glyph_data(wordform: str) -> list[tuple[str, str, str]]:\n",
    "    if wordform in SPECIAL_TOKENS:\n",
    "        return [(wordform, wordform, wordform)]\n",
    "\n",
    "    # Break wordform into morphemes\n",
    "    morphemes: list[str] = _split_wordform_into_morphemes(wordform)\n",
    "\n",
    "    # Get possible glyph names for each morpheme\n",
    "    morphemes_and_possible_glyph_names: list[tuple[str, list[str]]] = [\n",
    "        _get_morpheme_glyph_names(m) for m in morphemes\n",
    "    ]\n",
    "\n",
    "    # Only accept morphemes with exactly one glyph name\n",
    "    morphemes_and_glyph_names: list[tuple[str, str]] = []\n",
    "    for morpheme, possible_glyph_names in morphemes_and_possible_glyph_names:\n",
    "        glyph_name = UNK if len(possible_glyph_names) != 1 else possible_glyph_names[0]\n",
    "        morpheme = UNK if glyph_name == UNK else morpheme\n",
    "        morphemes_and_glyph_names.append((morpheme, glyph_name))\n",
    "\n",
    "        if glyph_name == UNK:\n",
    "            unk_readings_all.append(morpheme)\n",
    "        else:\n",
    "            non_unk_readings_all.append(morpheme)\n",
    "\n",
    "    # Now get the glyphs\n",
    "    morphemes_glyph_names_and_glyphs: list[tuple[str, str, str]] = []\n",
    "    for morpheme, glyph_name in morphemes_and_glyph_names:\n",
    "        if glyph_name == \"N\":\n",
    "            continue\n",
    "\n",
    "        if glyph_name in SWAP_GLYPH_NAMES:\n",
    "            glyph_name = SWAP_GLYPH_NAMES[glyph_name]\n",
    "\n",
    "        if morpheme == UNK:\n",
    "            morphemes_glyph_names_and_glyphs.append((UNK, UNK, UNK))\n",
    "        else:\n",
    "            unicode = _glyph_name_to_unicode(glyph_name)\n",
    "            if unicode == UNK or \"X\" in unicode:\n",
    "                morphemes_glyph_names_and_glyphs.append((UNK, UNK, UNK))\n",
    "            else:\n",
    "                morphemes_glyph_names_and_glyphs.append((morpheme, glyph_name, unicode))\n",
    "\n",
    "    return morphemes_glyph_names_and_glyphs\n",
    "\n",
    "\n",
    "def _split_wordform_into_morphemes(wf: str) -> list[str]:\n",
    "    if wf in NUMBERS_TO_READINGS:\n",
    "        wf_ = NUMBERS_TO_READINGS[wf]\n",
    "    elif wf.split(\"-\", 1)[0] in NUMBERS_TO_READINGS:\n",
    "        # cases like \"7-bi\"\n",
    "        split_ = wf.split(\"-\", 1)\n",
    "        wf_ = NUMBERS_TO_READINGS[split_[0]] + \"-\" + split_[1]\n",
    "    else:\n",
    "        wf_ = wf\n",
    "\n",
    "    # uri₅{ki} -> [uri₅, {ki}]\n",
    "    split_ = re.split(r\"(\\{.*?\\})\", wf_)\n",
    "\n",
    "    # Split on space, which should only happen if it\n",
    "    # is one of the number replacements below\n",
    "    split_ = [s.split(\" \") for s in split_ if s]\n",
    "    split_ = [s for sublist in split_ for s in sublist if s]  # Flatten\n",
    "\n",
    "    # Split on hyphens, but not within parentheses\n",
    "    split_ = [re.split(r\"-(?![^(]*\\))\", s) for s in split_ if s]\n",
    "    split_ = [s for sublist in split_ for s in sublist if s]  # Flatten\n",
    "\n",
    "    # split and reverse any morphemes with colons\n",
    "    # e.g. \"mu-lu:gal-e\" -> [\"mu\", \"gal\", \"lu\", \"e\"]\n",
    "    # split_ = [s.split(\":\")[::-1] if \":\" in s else [s] for s in split_ if s]\n",
    "    # split_ = [s for sublist in split_ for s in sublist if s]  # Flatten\n",
    "\n",
    "    return [s for s in split_ if s]\n",
    "\n",
    "\n",
    "NUMERIC_PATTERN = re.compile(r\"^\\d+(/\\d+)?(\\.\\d+)?(\\s*\\([^)]+\\))?$\")\n",
    "\n",
    "\n",
    "def _get_morpheme_glyph_names(morpheme: str) -> tuple[str, list[str]]:\n",
    "    # only want to do this when it stands on its own\n",
    "    morpheme = \"ŋeš₂\" if morpheme == \"geš₂\" else morpheme\n",
    "\n",
    "    if morpheme in [\"x\", \"n\", \"X\", \"N\"]:\n",
    "        return \"...\", [\"...\"]\n",
    "\n",
    "    # Numbers\n",
    "    if NUMERIC_PATTERN.match(morpheme):\n",
    "        return _get_number_glyph_names(morpheme)\n",
    "\n",
    "    # Already glyph name (reading uncertain)\n",
    "    if morpheme in GLYPH_NAMES:\n",
    "        return UNK, [morpheme]\n",
    "\n",
    "    # layup\n",
    "    morpheme_ = morpheme.replace(\"{\", \"\").replace(\"}\", \"\")  # {ki} -> ki\n",
    "    if morpheme_ in READING_TO_GLYPH_NAME:\n",
    "        return morpheme, READING_TO_GLYPH_NAME[morpheme_]\n",
    "\n",
    "    # Sign name but that sign is not in the list.\n",
    "    # But since sign names are based on a valid reading,\n",
    "    # we can lowercase it and check again to get the more standard glyph name.\n",
    "    # Note: the lowercase version may not be the right reading,\n",
    "    # but we'll use it anyway...\n",
    "    # It is the highest probability and introduces, I think,\n",
    "    # a desirable amount of noise\n",
    "    if morpheme.isupper():\n",
    "        morpheme_ = morpheme.lower()\n",
    "        if morpheme_.lower() in READING_TO_GLYPH_NAME:\n",
    "            return UNK, READING_TO_GLYPH_NAME[morpheme_]\n",
    "        # give up hope :/\n",
    "        unk_readings_sign_name.append(morpheme)\n",
    "        return UNK, []\n",
    "\n",
    "    if \"(\" in morpheme and \")\" in morpheme:\n",
    "        split_ = morpheme.split(\"(\")\n",
    "        morpheme_, glyph_name_ = split_[0], split_[1].replace(\")\", \"\")\n",
    "\n",
    "        if morpheme_ in READING_TO_GLYPH_NAME:\n",
    "            possible_glyph_names = READING_TO_GLYPH_NAME[morpheme_]\n",
    "            if len(possible_glyph_names) == 1:\n",
    "                return morpheme_, possible_glyph_names\n",
    "            if glyph_name_ in possible_glyph_names:\n",
    "                return morpheme_, [glyph_name_]\n",
    "\n",
    "        if glyph_name_ in GLYPH_NAME_TO_READINGS:\n",
    "            possible_readings = GLYPH_NAME_TO_READINGS[glyph_name_]\n",
    "            if len(possible_readings) == 1:\n",
    "                return possible_readings[0], [glyph_name_]\n",
    "\n",
    "    unk_reading_other.append(morpheme)\n",
    "    return morpheme, []\n",
    "\n",
    "\n",
    "def _get_number_glyph_names(morpheme: str) -> tuple[str, list[str]]:\n",
    "    if morpheme in READING_TO_GLYPH_NAME:\n",
    "        return morpheme, READING_TO_GLYPH_NAME[morpheme]\n",
    "    if morpheme.lower() in READING_TO_GLYPH_NAME:\n",
    "        return morpheme.lower(), READING_TO_GLYPH_NAME[morpheme.lower()]\n",
    "    if morpheme in GLYPH_NAMES:\n",
    "        return morpheme, [morpheme]\n",
    "\n",
    "    unk_readings_num.append(morpheme)\n",
    "    return morpheme, []\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ------------------------------- Glyphs -----------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "def _glyph_name_to_unicode(glyph_name: str) -> str:\n",
    "    if glyph_name in SPECIAL_TOKENS:\n",
    "        return glyph_name\n",
    "\n",
    "    if glyph_name not in GLYPH_NAME_TO_UNICODE:\n",
    "        glyph_names_not_in_map.append(glyph_name)\n",
    "        return UNK\n",
    "\n",
    "    unicode = GLYPH_NAME_TO_UNICODE[glyph_name]\n",
    "    if not unicode:\n",
    "        glyph_names_no_unicode.append(glyph_name)\n",
    "        return UNK\n",
    "\n",
    "    glyph_names_found_unicode.append(glyph_name)\n",
    "    return unicode\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ------------------------------- Reports  ---------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _print_report(x, title):\n",
    "    print()\n",
    "    print(f\"----- {title} -----\")\n",
    "    counter = Counter(x)\n",
    "    top_ = counter.most_common(20)\n",
    "    for token, count in top_:\n",
    "        print(f\" > {token} – {count}\")\n",
    "    print(\"Total: \", len(x))\n",
    "\n",
    "\n",
    "def _print_reading_to_glyph_name_stats():\n",
    "    num_unk_readings = len(unk_readings_all)\n",
    "    num_non_unk_readings = len(non_unk_readings_all)\n",
    "    num_all_morphemes = num_unk_readings + num_non_unk_readings\n",
    "    pct_unk = round(num_unk_readings / num_all_morphemes * 100, 2)\n",
    "    pct_non_unk = round(num_non_unk_readings / num_all_morphemes * 100, 2)\n",
    "    print()\n",
    "    print(f\"# of morphemes unable to convert: {num_unk_readings} ({pct_unk}%)\")\n",
    "    print(\n",
    "        f\"# of morphemes successfully converted: {num_non_unk_readings} ({pct_non_unk}%)\"\n",
    "    )\n",
    "    print()\n",
    "    _print_report(unk_readings_sign_name, \"UNK SIGN NAMES\")\n",
    "    _print_report(unk_readings_num, \"UNK NUMBERS\")\n",
    "    _print_report(unk_reading_other, \"UNK OTHER\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def _print_glyph_name_to_unicode_stats():\n",
    "    num_unable_to_convert = len(glyph_names_not_in_map) + len(glyph_names_no_unicode)\n",
    "    num_converted = len(glyph_names_found_unicode)\n",
    "    num_total = num_unable_to_convert + num_converted\n",
    "    pct_unable_to_convert = round(num_unable_to_convert / num_total * 100, 2)\n",
    "    pct_converted = round(num_converted / num_total * 100, 2)\n",
    "    print()\n",
    "    print(\n",
    "        f\"# of names unable to convert: {num_unable_to_convert} ({pct_unable_to_convert}%)\"\n",
    "    )\n",
    "    print(f\"# of names successfully converted: {num_converted} ({pct_converted}%)\")\n",
    "    print()\n",
    "    _print_report(glyph_names_not_in_map, \"NAME NOT IN glyph_name_to_glyph.json\")\n",
    "    _print_report(glyph_names_no_unicode, \"NO UNICODE\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# -------------------------- Postprocessing  -------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "def _drop_rows_with_identical_transliterations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print()\n",
    "    print(\"Dropping rows with identical transliterations...\")\n",
    "    # uncomment below to see which rows\n",
    "    # print(df[df[\"transliteration\"].map(df[\"transliteration\"].value_counts() > 1)])\n",
    "    prev_num_rows = len(df)\n",
    "    df = df.drop_duplicates(subset=[\"transliteration\"])\n",
    "    num_rows = len(df)\n",
    "    print(f\"Rows dropped: {prev_num_rows - num_rows}\")\n",
    "    print(f\"New number of rows: {num_rows}\")\n",
    "    print()\n",
    "    return df\n",
    "\n",
    "\n",
    "def _drop_rows_with_identical_glyphs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print()\n",
    "    print(\"Dropping rows with identical glyphs...\")\n",
    "    # uncomment below to see which rows\n",
    "    # print(df[df[\"glyphs\"].map(df[\"glyphs\"].value_counts() > 1)])\n",
    "    prev_num_rows = len(df)\n",
    "    df = df.drop_duplicates(subset=[\"glyphs\"])\n",
    "    num_rows = len(df)\n",
    "    print(f\"Rows dropped: {prev_num_rows - num_rows}\")\n",
    "    print(f\"New number of rows: {num_rows}\")\n",
    "    print()\n",
    "    return df\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# -------------------------- Stats / Out  ----------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "def _print_glyph_count(df: pd.DataFrame):\n",
    "    # Count glyphs\n",
    "    def _count_glyph(glyphs):\n",
    "        for special in SPECIAL_TOKENS:\n",
    "            glyphs = glyphs.replace(special, \"\")\n",
    "        glyphs = glyphs.replace(\" \", \"\")\n",
    "        return len(glyphs)\n",
    "\n",
    "    # print total glyph count\n",
    "    print()\n",
    "    print(\"Total glyphs:\", df[\"glyphs\"].map(_count_glyph).sum())\n",
    "    print()\n",
    "\n",
    "\n",
    "def _write(df: pd.DataFrame, separate_genre_files=False):\n",
    "    if separate_genre_files:\n",
    "        for genre in df[\"genre\"].unique():\n",
    "            genre_name = genre.replace(\"/\", \"\")\n",
    "            outfile_ = OUTFILE.replace(\".csv\", f\"_{genre_name}.csv\")\n",
    "            print(f\"Writing to {outfile_}...\")\n",
    "            df[df[\"genre\"] == genre].to_csv(outfile_, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"Writing to {OUTFILE}...\")\n",
    "    df.to_csv(OUTFILE, index=False, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def _save_glyph_to_observed_readings():\n",
    "    with open(\n",
    "        f\"{OUTPUT_DIR}/glyph_to_observed_readings.json\", \"w\", encoding=\"utf-8\"\n",
    "    ) as outfile:\n",
    "        json.dump(glyph_to_observed_readings, outfile, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
