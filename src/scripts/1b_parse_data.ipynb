{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse, validate, and save the data\n",
    "\n",
    "### Parsing and validation\n",
    "\n",
    "In this notebook, we read the JSON files provided by ePSD2 into Pydantic models.\n",
    "This provides a way to validate the data and ensure that it conforms to the expected format.\n",
    "\n",
    "Specifically:\n",
    "- The `Text` models are configured to forbid extra fields, so we can be\n",
    "sure that we are not leaving any data on the table.\n",
    "- Some of the fields have defaults. These keys are only present on some of the objects\n",
    "in the JSON, so we can use the defaults to fill in the missing values so that each\n",
    "has the same surface area.\n",
    "- Other fields do not have defaults, so those we can be sure are present on every object.\n",
    "- Finally, we also get type checking and whatever other validation we may want to add.\n",
    "\n",
    "When interacting with JSON directly, you don't get any guarantees about the data\n",
    "(what is present, what the type of the value is). This gives us these guarantees.\n",
    "\n",
    "### Collating and writing\n",
    "\n",
    "We then generate the transliteration for each, load all of the models into DataFrames,\n",
    "and write them to CSV files at \"outputs/1_<corpus_name>.csv\".\n",
    "\n",
    "These will be immediately inner joined into a single CSV in the next step,\n",
    "but having separate CSVs for each corpus is useful for debugging and for\n",
    "seeing all of the data that each provides (which varies based on corpus).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models.corpus import CorpusEnum, CorpusType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the corpus and text metadata from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading admin_ed12...\n",
      "✅ Loaded admin_ed12 (89 texts)\n",
      "\n",
      "Loading admin_ed3a...\n",
      "✅ Loaded admin_ed3a (840 texts)\n",
      "\n",
      "Loading admin_ed3b...\n",
      "✅ Loaded admin_ed3b (3477 texts)\n",
      "\n",
      "Loading admin_oakk...\n",
      "✅ Loaded admin_oakk (5472 texts)\n",
      "\n",
      "Loading admin_lagash2...\n",
      "✅ Loaded admin_lagash2 (769 texts)\n",
      "\n",
      "Loading admin_ur3...\n",
      "✅ Loaded admin_ur3 (80181 texts)\n",
      "\n",
      "Loading early_lit...\n",
      "✅ Loaded early_lit (43 texts)\n",
      "\n",
      "Loading oldbab_lit...\n",
      "✅ Loaded oldbab_lit (1254 texts)\n",
      "\n",
      "Loading royal...\n",
      "✅ Loaded royal (1928 texts)\n",
      "\n",
      "Loading incantations...\n",
      "✅ Loaded incantations (244 texts)\n",
      "\n",
      "Loading liturgies...\n",
      "✅ Loaded liturgies (96 texts)\n",
      "\n",
      "Loading udughul...\n",
      "✅ Loaded udughul (14 texts)\n",
      "\n",
      "Loading varia...\n",
      "✅ Loaded varia (3 texts)\n"
     ]
    }
   ],
   "source": [
    "def load_corpus_from_json(corpus: CorpusEnum) -> CorpusType:\n",
    "    \"\"\"\n",
    "    Load a Corpus from the ePSD2 data.\n",
    "    \"\"\"\n",
    "    print(f\"\\nLoading {corpus.value}...\")\n",
    "\n",
    "    project_root = Path.cwd().parents[1]\n",
    "    corpus_data_path = project_root / \"epsd2_data\" / corpus.value\n",
    "\n",
    "    if not os.path.exists(corpus_data_path):\n",
    "        print(f\"ERROR: {corpus_data_path} does not exist. Skipping...\")\n",
    "        return\n",
    "\n",
    "    # Get the list of directories that contain a catalogue.json file\n",
    "    # These are the directories that contain the JSON files for each tablet\n",
    "    corpusjson_dirs = [\n",
    "        root\n",
    "        for root, _, filenames in os.walk(corpus_data_path)\n",
    "        if \"catalogue.json\" in filenames\n",
    "    ]\n",
    "    if not corpusjson_dirs:\n",
    "        print(\n",
    "            f\"ERROR: No catalogue.json files found in {corpus_data_path}. Skipping...\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Parse the catalogue.json file\n",
    "    target_dir = corpusjson_dirs[0]\n",
    "    catalogue_path = Path(target_dir) / \"catalogue.json\"\n",
    "    with open(catalogue_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        catalogue = json.load(f)\n",
    "\n",
    "    # Use the catalogue to get the list of tablets\n",
    "    tablets_path = str(Path(target_dir) / \"corpusjson/\")\n",
    "    texts = [\n",
    "        {\"dir_path\": tablets_path, **text_data}\n",
    "        for text_data in catalogue[\"members\"].values()\n",
    "    ]\n",
    "\n",
    "    model = corpus.model(texts=texts)\n",
    "    print(f\"✅ Loaded {corpus.value} ({len(model.texts)} texts)\")\n",
    "    return model\n",
    "\n",
    "\n",
    "corpora = [load_corpus_from_json(corpus) for corpus in CorpusEnum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the text content from JSON\n",
    "\n",
    "This is stored in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusAdminEd1and2'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:00<00:00, 1411.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 89 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusAdminEd3a'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:01<00:00, 626.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 840 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusAdminEd3b'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3477/3477 [00:06<00:00, 521.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 3477 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusAdminOldAkk'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5472/5472 [00:05<00:00, 947.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 5472 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusAdminLagash2'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 769/769 [00:00<00:00, 1412.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 769 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusAdminUr3'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80181/80181 [02:57<00:00, 452.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 80181 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusLiteraryEarly'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 346.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 43 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusLiteraryOldBab'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [00:03<00:00, 364.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 1022 texts\n",
      "❌ Failed to load 232 texts:\n",
      "Q000353\n",
      "Q000355\n",
      "Q000370\n",
      "Q000378\n",
      "Q000402\n",
      "Q000403\n",
      "Q000405\n",
      "Q000411\n",
      "Q000428\n",
      "Q000429\n",
      "Q000437\n",
      "Q000441\n",
      "Q000442\n",
      "Q000443\n",
      "Q000445\n",
      "Q000456\n",
      "Q000457\n",
      "Q000462\n",
      "Q000464\n",
      "Q000468\n",
      "Q000470\n",
      "Q000474\n",
      "Q000475\n",
      "Q000477\n",
      "Q000486\n",
      "Q000487\n",
      "Q000489\n",
      "Q000503\n",
      "Q000504\n",
      "Q000505\n",
      "Q000535\n",
      "Q000551\n",
      "Q000552\n",
      "Q000567\n",
      "Q000568\n",
      "Q000569\n",
      "Q000570\n",
      "Q000571\n",
      "Q000572\n",
      "Q000585\n",
      "Q000587\n",
      "Q000588\n",
      "Q000589\n",
      "Q000590\n",
      "Q000591\n",
      "Q000595\n",
      "Q000596\n",
      "Q000597\n",
      "Q000598\n",
      "Q000600\n",
      "Q000601\n",
      "Q000602\n",
      "Q000603\n",
      "Q000605\n",
      "Q000606\n",
      "Q000607\n",
      "Q000608\n",
      "Q000609\n",
      "Q000610\n",
      "Q000617\n",
      "Q000620\n",
      "Q000642\n",
      "Q000645\n",
      "Q000648\n",
      "Q000650\n",
      "Q000654\n",
      "Q000657\n",
      "Q000663\n",
      "Q000665\n",
      "Q000666\n",
      "Q000667\n",
      "Q000685\n",
      "Q000693\n",
      "Q000696\n",
      "Q000698\n",
      "Q000703\n",
      "Q000704\n",
      "Q000705\n",
      "Q000706\n",
      "Q000718\n",
      "Q000724\n",
      "Q000728\n",
      "Q000729\n",
      "Q000730\n",
      "Q000731\n",
      "Q000735\n",
      "Q000740\n",
      "Q000742\n",
      "Q000744\n",
      "Q000745\n",
      "Q000753\n",
      "Q000754\n",
      "Q000755\n",
      "Q000756\n",
      "Q000757\n",
      "Q000758\n",
      "Q000759\n",
      "Q000760\n",
      "Q000761\n",
      "Q000763\n",
      "Q000764\n",
      "Q000765\n",
      "Q000767\n",
      "Q000768\n",
      "Q000769\n",
      "Q000770\n",
      "Q000771\n",
      "Q000772\n",
      "Q000773\n",
      "Q000774\n",
      "Q000780\n",
      "Q000783\n",
      "Q000787\n",
      "Q000826\n",
      "Q000827\n",
      "Q000828\n",
      "Q000829\n",
      "Q002287\n",
      "Q002288\n",
      "Q002289\n",
      "Q002290\n",
      "Q002291\n",
      "Q002292\n",
      "Q002293\n",
      "Q002294\n",
      "Q002295\n",
      "Q002296\n",
      "Q002297\n",
      "Q002298\n",
      "Q002299\n",
      "Q002300\n",
      "Q002301\n",
      "Q002302\n",
      "Q002303\n",
      "Q002304\n",
      "Q002305\n",
      "Q002306\n",
      "Q002307\n",
      "Q002308\n",
      "Q002309\n",
      "Q002310\n",
      "Q002311\n",
      "Q002312\n",
      "Q002313\n",
      "Q002314\n",
      "Q002315\n",
      "Q002316\n",
      "Q002317\n",
      "Q002318\n",
      "Q002319\n",
      "Q002320\n",
      "Q002321\n",
      "Q002322\n",
      "Q002323\n",
      "Q002324\n",
      "Q002325\n",
      "Q002326\n",
      "Q002327\n",
      "Q002328\n",
      "Q002329\n",
      "Q002330\n",
      "Q002331\n",
      "Q002332\n",
      "Q002341\n",
      "Q002342\n",
      "Q002343\n",
      "Q002344\n",
      "Q002345\n",
      "Q002346\n",
      "Q002347\n",
      "Q002348\n",
      "Q002349\n",
      "Q002350\n",
      "Q002351\n",
      "Q002352\n",
      "Q002353\n",
      "Q002354\n",
      "Q002355\n",
      "Q002356\n",
      "Q002357\n",
      "Q002358\n",
      "Q002359\n",
      "Q002361\n",
      "Q002362\n",
      "Q002363\n",
      "Q002364\n",
      "Q002365\n",
      "Q002366\n",
      "Q002367\n",
      "Q002368\n",
      "Q002369\n",
      "Q002370\n",
      "Q002371\n",
      "Q002372\n",
      "Q002373\n",
      "Q002374\n",
      "Q002375\n",
      "Q002376\n",
      "Q002377\n",
      "Q002378\n",
      "Q002379\n",
      "Q002380\n",
      "Q002381\n",
      "Q002382\n",
      "Q002383\n",
      "Q002384\n",
      "Q002385\n",
      "Q002386\n",
      "Q002387\n",
      "Q002388\n",
      "Q002389\n",
      "Q002390\n",
      "Q002391\n",
      "Q002392\n",
      "Q002393\n",
      "Q002394\n",
      "Q002395\n",
      "Q002396\n",
      "Q002397\n",
      "Q002398\n",
      "Q002399\n",
      "Q002400\n",
      "Q002402\n",
      "Q002403\n",
      "Q002404\n",
      "Q002405\n",
      "Q002406\n",
      "Q002409\n",
      "Q003580\n",
      "Q003581\n",
      "Q004808\n",
      "Q009248\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusRoyal'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1928/1928 [02:20<00:00, 13.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 1928 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusIncantations'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244/244 [00:00<00:00, 416.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 244 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusLiturgies'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:00<00:00, 337.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 96 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusUdughul'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 91.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 14 texts\n",
      "\n",
      "Loading text content for <class 'src.models.corpus.Corpus.CorpusVaria'>...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 369.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 3 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_text_content(corpus: CorpusType) -> None:\n",
    "    \"\"\"\n",
    "    Load the content of a text.\n",
    "    \"\"\"\n",
    "    print(f\"\\nLoading text content for {type(corpus)}...\")\n",
    "\n",
    "    success = []\n",
    "    failed = []\n",
    "\n",
    "    for text in tqdm(corpus.texts):\n",
    "        try:\n",
    "            text.load_contents()\n",
    "            success.append(text.file_id)\n",
    "        except Exception:\n",
    "            failed.append(text.file_id)\n",
    "\n",
    "    print(f\"✅ Successfully loaded {len(success)} texts\")\n",
    "    if len(failed) > 0:\n",
    "        print(f\"❌ Failed to load {len(failed)} texts:\")\n",
    "        print(\"\\n\".join(failed))\n",
    "\n",
    "\n",
    "for corpus in corpora:\n",
    "    load_text_content(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate transliterations and save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pd(corpus: CorpusType) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert the corpus to a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    texts = [\n",
    "        {\n",
    "            \"id\": text.file_id,\n",
    "            \"transliteration\": text.transliteration(),\n",
    "            **text.model_dump(exclude={\"cdl\"}),\n",
    "        }\n",
    "        for text in corpus.texts\n",
    "    ]\n",
    "    df = pd.DataFrame(texts).fillna(\"\")\n",
    "    df.set_index(\"id\", inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "dfs = [(type(corpus).__name__, to_pd(corpus)) for corpus in corpora]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing CorpusAdminEd1and2 to CSV...\n",
      "✅ Wrote CorpusAdminEd1and2 to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusAdminEd1and2.csv\n",
      "\n",
      "Writing CorpusAdminEd3a to CSV...\n",
      "✅ Wrote CorpusAdminEd3a to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusAdminEd3a.csv\n",
      "\n",
      "Writing CorpusAdminEd3b to CSV...\n",
      "✅ Wrote CorpusAdminEd3b to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusAdminEd3b.csv\n",
      "\n",
      "Writing CorpusAdminOldAkk to CSV...\n",
      "✅ Wrote CorpusAdminOldAkk to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusAdminOldAkk.csv\n",
      "\n",
      "Writing CorpusAdminLagash2 to CSV...\n",
      "✅ Wrote CorpusAdminLagash2 to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusAdminLagash2.csv\n",
      "\n",
      "Writing CorpusAdminUr3 to CSV...\n",
      "✅ Wrote CorpusAdminUr3 to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusAdminUr3.csv\n",
      "\n",
      "Writing CorpusLiteraryEarly to CSV...\n",
      "✅ Wrote CorpusLiteraryEarly to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusLiteraryEarly.csv\n",
      "\n",
      "Writing CorpusLiteraryOldBab to CSV...\n",
      "✅ Wrote CorpusLiteraryOldBab to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusLiteraryOldBab.csv\n",
      "\n",
      "Writing CorpusRoyal to CSV...\n",
      "✅ Wrote CorpusRoyal to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusRoyal.csv\n",
      "\n",
      "Writing CorpusIncantations to CSV...\n",
      "✅ Wrote CorpusIncantations to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusIncantations.csv\n",
      "\n",
      "Writing CorpusLiturgies to CSV...\n",
      "✅ Wrote CorpusLiturgies to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusLiturgies.csv\n",
      "\n",
      "Writing CorpusUdughul to CSV...\n",
      "✅ Wrote CorpusUdughul to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusUdughul.csv\n",
      "\n",
      "Writing CorpusVaria to CSV...\n",
      "✅ Wrote CorpusVaria to /Users/cole/dev/sumerian/SumTablets/outputs/1_CorpusVaria.csv\n"
     ]
    }
   ],
   "source": [
    "def write_to_csv(name: str, df: pd.DataFrame) -> None:\n",
    "    print(f\"\\nWriting {name} to CSV...\")\n",
    "    project_root = Path.cwd().parents[1]\n",
    "    output_path = project_root / \"outputs\"\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    output_path = output_path / f\"1_{name}.csv\"\n",
    "    df.to_csv(output_path)\n",
    "    print(f\"✅ Wrote {name} to {output_path}\")\n",
    "\n",
    "\n",
    "for name, df in dfs:\n",
    "    write_to_csv(name, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
