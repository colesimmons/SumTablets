{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under construction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script cleans the transliterations in a new \"transliteration_clean\" column\n",
    "(for easy comparison) and saves the result to a new csv file.\n",
    "\n",
    "All uncaught cases are printed, prefixed with \"!!!\".\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from enum import Enum\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.constants import OUTPUT_DIR\n",
    "\n",
    "INFILE = f\"{OUTPUT_DIR}/2_tablets.csv\"\n",
    "OUTFILE = f\"{OUTPUT_DIR}/3_cleaned_transliterations.csv\"\n",
    "\n",
    "\n",
    "class SpecialTokensBefore(Enum):\n",
    "    MISSING = \"#MISSING#\"\n",
    "    SURFACE = \"#SURFACE#\"\n",
    "    COLUMN = \"#COLUMN#\"\n",
    "    BLANK_SPACE = \"#BLANK_SPACE#\"\n",
    "    RULING = \"#RULING#\"\n",
    "    NEWLINE = \"\\n\"\n",
    "\n",
    "\n",
    "class SpecialTokensAfter(Enum):\n",
    "    MISSING = \"...\"\n",
    "    SURFACE = \"<SURFACE>\"\n",
    "    COLUMN = \"<COLUMN>\"\n",
    "    BLANK_SPACE = \"<BLANK_SPACE>\"\n",
    "    RULING = \"<RULING>\"\n",
    "    NEWLINE = \"\\n\"\n",
    "\n",
    "\n",
    "# for easier reference\n",
    "MISSING = SpecialTokensBefore.MISSING.value\n",
    "\n",
    "# key for new column\n",
    "KEY = \"transliteration_clean\"\n",
    "\n",
    "FunctionAndDesc = Tuple[Callable[[pd.Series], pd.Series], str]\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(INFILE).fillna(\"\")\n",
    "    df[KEY] = df[\"transliteration\"]\n",
    "\n",
    "    collapse = (\n",
    "        _collapse_whitespace_hyphens_missing,\n",
    "        \"Collapsing whitespace/hyphens/missing...\",\n",
    "    )\n",
    "\n",
    "    fns: List[FunctionAndDesc] = [\n",
    "        # ------ (1) easy wins -----\n",
    "        (\n",
    "            _double_angle_brackets,\n",
    "            'Treating <<abc>> as normal text (\"present but must be excised\")...',\n",
    "        ),\n",
    "        (\n",
    "            _upper_brackets,\n",
    "            \"Treating upper brackets as normal text (partial breakage)...\",\n",
    "        ),\n",
    "        (_double_curly_braces, \"Getting rid of {{abc}} (linguistic glosses)...\"),\n",
    "        collapse,\n",
    "        (_sanity_check_1, \"Performing first sanity check...\"),\n",
    "        #\n",
    "        # ------ (2) enclosures out of order -----\n",
    "        (_check_for_unmatched_brackets, \"Checking for unmatched brackets...\"),\n",
    "        (\n",
    "            _fix_enclosure_order,\n",
    "            \"Fixing enclosure order, e.g. ([abc)def] -> [(abc)def]...\",\n",
    "        ),\n",
    "        #\n",
    "        # ------ (3) other elements -----\n",
    "        (\n",
    "            _single_angle_brackets,\n",
    "            'Getting rid of <abc> (\"must be supplied but not present\")...',\n",
    "        ),\n",
    "        (_semicolons, \"Converting semicolons to newlines...\"),\n",
    "        (_single_curly_braces, \"Removing hyphens like -} and {-...\"),\n",
    "        (_vertical_bars, \"Adding hyphens after pairs of vertical bars...\"),\n",
    "        (_parentheses, \"Adding hyphens after parentheses...\"),\n",
    "        collapse,\n",
    "        (_sanity_check_2, \"Performing second sanity check...\"),\n",
    "        #\n",
    "        # ------ (4) MISSING -----\n",
    "        (_single_square_brackets, \"[abc] -> MISSING\"),\n",
    "        # run this a few times\n",
    "        (_x_o_n, \"x, o, and n -> MISSING\"),\n",
    "        (_x_o_n, \"x, o, and n -> MISSING\"),\n",
    "        (_x_o_n, \"x, o, and n -> MISSING\"),\n",
    "        (_dollar_signs, \"$abc$ -> MISSING\"),\n",
    "        (_ellipses, \"... -> MISSING\"),\n",
    "        (\n",
    "            _standalone_parens,\n",
    "            \"Getting rid of standalone parens (may be present but not certain)\",\n",
    "        ),\n",
    "        collapse,\n",
    "        (_sanity_check_3, \"Performing third sanity check...\"),\n",
    "        #\n",
    "        # ------ (5) enclosures -----\n",
    "        (_missing_alone_in_enclosure, \"Getting rid of (#MISSING#) and {#MISSING#}\"),\n",
    "        (_empty_enclosures, \"Removing empty {} and ()\"),\n",
    "        collapse,\n",
    "        #\n",
    "        # ------ (6) final -----\n",
    "        (_sanity_check_final, \"Performing final sanity check...\"),\n",
    "        (_convert_special_tokens, \"Converting special tokens...\"),\n",
    "    ]\n",
    "    for func, desc in fns:\n",
    "        print(\"\\n➡️ \" + desc)\n",
    "        df = df.apply(func, axis=1)\n",
    "\n",
    "    # Remove tablets with no transliteration\n",
    "    df = _remove_tablets_with_no_transliteration(df)\n",
    "\n",
    "    print(f\"Writing to {OUTFILE}...\")\n",
    "    df.to_csv(OUTFILE, index=False)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ---------------------------- easy wins -----------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "def _double_angle_brackets(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    'The graphemes are present but must be excised for the sense.'\n",
    "    From: https://oracc.museum.upenn.edu/doc/help/editinginatf/primer/inlinetutorial/index.html\n",
    "\n",
    "    Get rid of the brackets but keep the text (i.e. treat it like normal text)\n",
    "    \"\"\"\n",
    "    row[KEY] = row[KEY].replace(\"<<\", \"\")\n",
    "    row[KEY] = row[KEY].replace(\">>\", \"\")\n",
    "    return row\n",
    "\n",
    "\n",
    "def _upper_brackets(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    ⸢abc⸣ is partially broken. Treat it as normal text.\n",
    "    \"\"\"\n",
    "    row[KEY] = row[KEY].replace(\"⸢\", \"\")\n",
    "    row[KEY] = row[KEY].replace(\"⸣\", \"\")\n",
    "    return row\n",
    "\n",
    "\n",
    "def _double_curly_braces(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    'Linguistic glosses are defined for the purposes of this specification\n",
    "     as glosses which give an alternative to the word(s) in question.\n",
    "     Such alternatives are typically either variants or translations.'\n",
    "    From: https://oracc.museum.upenn.edu/doc/help/editinginatf/primer/inlinetutorial/index.html\n",
    "\n",
    "    Get rid of 'em.\n",
    "    \"\"\"\n",
    "    pattern = r\"\\{\\{[^\\n]*?\\}\\}\"\n",
    "    matches = re.findall(pattern, row[KEY])\n",
    "    for match in matches:\n",
    "        print(\">> \", match, f\" ({row['id']})\")\n",
    "        row[KEY] = row[KEY].replace(match, \"\")\n",
    "\n",
    "    pattern = r\"\\n[^\\n]*?\\}\\}\"\n",
    "    matches = re.findall(pattern, row[KEY])\n",
    "    for match in matches:\n",
    "        print(\">> \", match.replace(\"\\n\", \"\"), f\" ({row['id']})\")\n",
    "        row[KEY] = row[KEY].replace(match, \"\\n\")\n",
    "\n",
    "    if \"{{\" in row[KEY] or \"}}\" in row[KEY]:\n",
    "        print(f\"Uncaught in {row['id']}\")\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def _collapse_whitespace_hyphens_missing(row: pd.Series) -> pd.Series:\n",
    "    # Newlines\n",
    "    row[KEY] = re.sub(r\"([\\ \\-]*\\n[\\ \\-]*)+\", \"\\n\", row[KEY])\n",
    "    # Spaces\n",
    "    row[KEY] = re.sub(r\"([\\-]*\\ [\\-]*)+\", \" \", row[KEY])\n",
    "    # Hyphens\n",
    "    row[KEY] = re.sub(r\"\\-+\", \"-\", row[KEY])\n",
    "    # MISSING\n",
    "    row[KEY] = re.sub(r\"([\\ \\-]*#MISSING#[\\ \\-]*)+\", MISSING, row[KEY])\n",
    "    row[KEY] = re.sub(r\"(\\n#MISSING#(?=\\n))+\", f\"\\n{MISSING}\", row[KEY])\n",
    "    return row\n",
    "\n",
    "\n",
    "DISALLOWED_1 = [\"<<\", \">>\", \"⸢\", \"⸣\", \"{{\", \"}}\"]\n",
    "\n",
    "\n",
    "def _sanity_check_1(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"Characters that should not be present at this point\"\"\"\n",
    "    for char in DISALLOWED_1:\n",
    "        if char in row[KEY]:\n",
    "            print(f\"!!! Disallowed character {char} in: {row['id']}\")\n",
    "    return row\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ---------------------------- enclosures ----------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "def _check_for_unmatched_brackets(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"A shortcoming of the EPSD data is that when I pull the transliterations,\n",
    "    brackets that occur in tandem with an \"n\", a parenthesis, or a vertical bar\n",
    "    are ommited.\n",
    "    \"\"\"\n",
    "\n",
    "    # Currently the only case where this happens...\n",
    "    if row[\"id\"] == \"P343022\":\n",
    "        row[KEY] = row[KEY].replace(\" [x x x\\n\", f\"{MISSING}\\n\")\n",
    "\n",
    "    for line in row[KEY].split(\"\\n\"):\n",
    "        # Get rid of everything except brackets\n",
    "        bracket_seq = \"\".join([c for c in line if c in \"[]\"])\n",
    "        # Get rid of all pairs of brackets\n",
    "        while True:\n",
    "            bracket_seq = bracket_seq.replace(\"[]\", \"\")\n",
    "            if \"[]\" not in bracket_seq:\n",
    "                break\n",
    "        if bracket_seq:\n",
    "            print(\"!!! Uncaught in: \", row[\"id\"])\n",
    "            print(\">> \", line)\n",
    "            print()\n",
    "        return row\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def _fix_enclosure_order(row: pd.Series) -> pd.Series:\n",
    "    # Note: only allowing x, space, and hyphen characters in the first case\n",
    "    # because double parens can really mess things up\n",
    "\n",
    "    text = row[KEY]\n",
    "\n",
    "    # Case 1: ([...)...] -> [(...)...]\n",
    "    matches = re.findall(\n",
    "        r\"(\\(\\[\"  # ([\n",
    "        + r\"[\\-\\ x]*?\"  # any character except: \\n ) ]\n",
    "        + r\"\\)\"  # )\n",
    "        + r\"[\\-\\ x]*?\"  # any character except: \\n ) ]\n",
    "        + r\"\\])\",  # ]\n",
    "        text,\n",
    "    )\n",
    "    for match in matches:\n",
    "        after = match.replace(\"([\", \"[(\")\n",
    "        print(f\">> 1. {match} -> {after}\")\n",
    "        text = text.replace(match, after)\n",
    "\n",
    "    # Case 2: [...(...]) -> [...(...)]\n",
    "    matches = re.findall(\n",
    "        r\"(\\[\"  # [\n",
    "        + r\"[^\\n(\\]]*?\"  # any character except: \\n ( ]\n",
    "        + r\"\\(\"  # (\n",
    "        + r\"[^\\n)\\]]*?\"  # any character except: \\n ) ]\n",
    "        + r\"\\]\\))\",  # ]\n",
    "        text,\n",
    "    )\n",
    "    for match in matches:\n",
    "        after = match.replace(\"])\", \")]\")\n",
    "        print(f\">> 2. {match} -> {after}\")\n",
    "        text = text.replace(match, after)\n",
    "\n",
    "    # Case 3: {[...}...] -> [{...}...]\n",
    "    matches = re.findall(\n",
    "        r\"(\\{\\[\"  # {[\n",
    "        + r\"[^\\n}\\]]*?\"  # any character except: \\n } ]\n",
    "        + r\"\\}\"  # }\n",
    "        + r\"[^\\n\\]]*?\"  # any character except: \\n ]\n",
    "        + r\"\\])\",  # closing bracket\n",
    "        text,\n",
    "    )\n",
    "    for match in matches:\n",
    "        after = match.replace(\"{[\", \"[{\")\n",
    "        print(f\">> 3. {match} -> {after}\")\n",
    "        text = text.replace(match, after)\n",
    "\n",
    "    # Case 4: [...{...]} -> [...{...}]\n",
    "    matches = re.findall(\n",
    "        r\"(\\[\"  # [\n",
    "        + r\"[^\\n{\\]]*?\"  # any character except: \\n { ]\n",
    "        + r\"\\{\"  # {\n",
    "        + r\"[^\\n\\]]*?\"  # any character except: \\n ]\n",
    "        + r\"\\]\\})\",  # }]\n",
    "        text,\n",
    "    )\n",
    "    for match in matches:\n",
    "        after = match.replace(\"]}\", \"}]\")\n",
    "        print(f\">> 4. {match} -> {after}\")\n",
    "        text = text.replace(match, after)\n",
    "\n",
    "    # Case 5: <...{...>} -> <...{...}>\n",
    "    matches = re.findall(\n",
    "        r\"(\\<\"  # <\n",
    "        + r\"[^\\n{\\>]*?\"  # any character except: \\n { >\n",
    "        + r\"\\{\"  # {\n",
    "        + r\"[^\\n}\\>]*?\"  # any character except: \\n } >\n",
    "        + r\"\\>\\})\",  # >}\n",
    "        text,\n",
    "    )\n",
    "    for match in matches:\n",
    "        after = match.replace(\">}\", \"}>\")\n",
    "        print(f\">> 5. {match} -> {after}\")\n",
    "        text = text.replace(match, after)\n",
    "\n",
    "    # Case 6: {<...}...> -> <{...}...>\n",
    "    matches = re.findall(\n",
    "        r\"(\\{\\<\" + r\"[^\\n\\}\\>]*?\" + r\"\\})\",\n",
    "        text,\n",
    "    )\n",
    "    for match in matches:\n",
    "        after = match.replace(\"{<\", \"<{\")\n",
    "        print(f\">> 6. {match} -> {after}\")\n",
    "        text = text.replace(match, after)\n",
    "\n",
    "    if row[\"id\"] == \"P324221\":\n",
    "        text = text.replace(\"[ma-da za-ab-ša-li{<ki]>}\", \"[ma-da za-ab-ša-li<{ki}>]\")\n",
    "\n",
    "    row[KEY] = text\n",
    "    return row\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# -------------------------- other elements --------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "def _single_angle_brackets(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    'The graphemes must be supplied for the sense but are not present.'\n",
    "    From: https://oracc.museum.upenn.edu/doc/help/editinginatf/primer/inlinetutorial/index.html\n",
    "\n",
    "    Get rid of 'em.\n",
    "    \"\"\"\n",
    "    text = row[KEY]\n",
    "\n",
    "    # Normal case\n",
    "    text = re.sub(r\"<[^\\n]*?>\", \"\", text)\n",
    "    # Unmatched opening: <abc\\n. Get rid of rest of line\n",
    "    text = re.sub(r\"(<[^\\n>]*?(\\n|$))\", f\"{MISSING}\\n\", text)\n",
    "    # Unmatched closing: \\n abc>. Get rid of start of line\n",
    "    text = re.sub(r\"((\\n|^)[^\\n<]*?>)\", f\"\\n{MISSING}\", text)\n",
    "\n",
    "    row[KEY] = text\n",
    "    return row\n",
    "\n",
    "\n",
    "def _semicolons(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"Semicolons are used to separate lines in the transliteration.\"\"\"\n",
    "    row[KEY] = row[KEY].replace(\";\", \"\\n\")\n",
    "    return row\n",
    "\n",
    "\n",
    "def _single_curly_braces(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    'Determinatives include semantic and phonetic modifiers,\n",
    "     which may be single graphemes or several hyphenated graphemes,\n",
    "     which are part of the current word.\n",
    "\n",
    "     Determinatives are enclosed in single brackets {...};\n",
    "     semantic determinatives require no special marking,\n",
    "     but phonetic glosses and determinatives should be indicated by adding\n",
    "     a plus sign (+) immediately after the opening brace, e.g., AN{+e}.\n",
    "\n",
    "     Multiple separate determinatives must be enclosed in their own brackets,\n",
    "     but a single determinative may consist of more than one sign\n",
    "     (as is the case with Early Dynastic pronunciation glosses).'\n",
    "    From: https://oracc.museum.upenn.edu/doc/help/editinginatf/primer/inlinetutorial/index.html\n",
    "    \"\"\"\n",
    "    # TODO: needed?\n",
    "    row[KEY] = row[KEY].replace(\"{-\", \"{\")\n",
    "    row[KEY] = row[KEY].replace(\"-}\", \"}\")\n",
    "    return row\n",
    "\n",
    "\n",
    "def _vertical_bars(row: pd.Series) -> pd.Series:\n",
    "    # Add hyphen after vertical bars\n",
    "    matches = re.findall(r\"(\\|[^|a-z]*?\\|)\", row[KEY])\n",
    "    for match in matches:\n",
    "        if \"-\" in match:\n",
    "            print(f\"!!! Uncaught hyphen in vertical bars: {match} ({row['id']})\")\n",
    "            match = match.replace(\"-\", \"\")\n",
    "        after = match + \"-\"\n",
    "        row[KEY] = row[KEY].replace(match, after)\n",
    "        print(f\">> {match} -> {after} ({row['id']})\")\n",
    "    return row\n",
    "\n",
    "\n",
    "def _parentheses(row: pd.Series) -> pd.Series:\n",
    "    text = row[KEY]\n",
    "    # -) -> )-\n",
    "    text = re.sub(r\"\\-+\\)\", \")-\", text)\n",
    "    # Insert a hyphen after each closing parenthesis if the next character is not whitespace\n",
    "    # (abc)def -> (abc)-def\n",
    "    text = re.sub(r\"\\)([a-zA-Z])\", r\")-\\1\", text)\n",
    "    # (- -> (\n",
    "    text = text.replace(\"(-\", \"(\")\n",
    "    row[KEY] = text\n",
    "    return row\n",
    "\n",
    "\n",
    "DISALLOWED_2 = [\"<\", \">\", \"(-\", \"-)\", \"{-\", \"-}\"]\n",
    "\n",
    "\n",
    "def _sanity_check_2(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"Characters that should not be present at this point\"\"\"\n",
    "    for char in DISALLOWED_2:\n",
    "        if char in row[KEY]:\n",
    "            print(f\"!!! Disallowed character {char} in: {row['id']}\")\n",
    "    return row\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ----------------------------- MISSING ------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "def _single_square_brackets(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    [abc def] is conjecture on what has been broken away.\n",
    "    Convert to SpecialToken.MISSING\n",
    "    \"\"\"\n",
    "    # [abc def] -> <MISSING>\n",
    "    row[KEY] = re.sub(r\"\\[[^\\[\\]\\n]*?\\]\", MISSING, row[KEY])\n",
    "    # Do it twice because of nested brackets\n",
    "    row[KEY] = re.sub(r\"\\[[^\\[\\]\\n]*?\\]\", MISSING, row[KEY])\n",
    "\n",
    "    # we made sure there were no unmatched brackets eariler,\n",
    "    # but then converted semicolons to newlines\n",
    "\n",
    "    # abc [def..\\n -> abc <MISSING>\\n\n",
    "    row[KEY] = re.sub(r\"\\[[^\\[\\]\\n]*?\\n\", f\"{MISSING}\\n\", row[KEY])\n",
    "    # \\n ...abc] def -> \\n<MISSING> def\n",
    "    row[KEY] = re.sub(r\"\\n[^\\[\\]\\n]*?\\]\", f\"\\n{MISSING}\", row[KEY])\n",
    "    return row\n",
    "\n",
    "\n",
    "def _x_o_n(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Both \"x\" and \"o\" are used to indicate missing text.\n",
    "    Convert sequences to SpecialToken.MISSING.\n",
    "\n",
    "    \"n\" on its own means that the quantity cannot be determined.\n",
    "    \"\"\"\n",
    "    row[KEY] = re.sub(r\"([\\ \\-\\n])([xXnNo])(?=[\\ \\-\\n]|$)\", r\"\\1\" + MISSING, row[KEY])\n",
    "\n",
    "    for char in [\"x\", \"o\", \"n\", \"X\", \"O\", \"N\"]:\n",
    "        row[KEY] = row[KEY].replace(f\"({char})\", MISSING)\n",
    "        row[KEY] = row[KEY].replace(f\"[{char}]\", MISSING)\n",
    "        row[KEY] = row[KEY].replace(f\"({char})\", MISSING)\n",
    "        row[KEY] = row[KEY].replace(f\"[{char}]\", MISSING)\n",
    "        row[KEY] = row[KEY].replace(f\"-{char}-\", f\" {MISSING} \")\n",
    "        row[KEY] = row[KEY].replace(f\" {char}-\", f\" {MISSING} \")\n",
    "        row[KEY] = row[KEY].replace(f\"-{char} \", f\" {MISSING} \")\n",
    "        row[KEY] = row[KEY].replace(f\" {char} \", f\" {MISSING} \")\n",
    "        row[KEY] = row[KEY].replace(f\"\\n{char} \", f\"\\n{MISSING} \")\n",
    "        row[KEY] = row[KEY].replace(f\" {char}\\n\", f\" {MISSING}\\n\")\n",
    "        row[KEY] = row[KEY].replace(rf\" {char}$\", MISSING)\n",
    "        row[KEY] = row[KEY].replace(rf\"-{char}$\", MISSING)\n",
    "        row[KEY] = row[KEY].replace(rf\"{MISSING}{char} \", MISSING)\n",
    "        row[KEY] = row[KEY].replace(rf\"{MISSING}{char}-\", MISSING)\n",
    "        row[KEY] = row[KEY].replace(rf\" {char}{MISSING}\", MISSING)\n",
    "        row[KEY] = row[KEY].replace(rf\"-{char}{MISSING}\", MISSING)\n",
    "\n",
    "    if row[\"id\"] == \"P010855\":\n",
    "        row[KEY] = row[KEY].replace(\"x:ur\", f\"ur{MISSING}\")\n",
    "    if row[\"id\"] == \"P278368\":\n",
    "        row[KEY] = row[KEY].replace(\"-x/EREN\", MISSING)\n",
    "    if row[\"id\"] == \"P323466\":\n",
    "        row[KEY] = row[KEY].replace(\"|3xAN|\", \"|AN.AN.AN|\")\n",
    "    if row[\"id\"] == \"P467714\":\n",
    "        row[KEY] = row[KEY].replace(\"x)\", MISSING + \")\")\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def _dollar_signs(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    $erasure$ or $ traces $ -> SpecialToken.MISSING\n",
    "\n",
    "    The other instances precede a sign name to indicate that the reading is uncertain.\n",
    "    Since we will take the presence of a sign name to mean that the reading is uncertain,\n",
    "    we can remove the $ signs and treat the text as normal.\n",
    "    e.g. $AN -> AN\n",
    "    \"\"\"\n",
    "\n",
    "    for str_ in [\n",
    "        \"$ traces $\",\n",
    "        \"($erasure$)\",\n",
    "        \"$erasure$\",\n",
    "        \"$AN\",\n",
    "        \"$MU\",\n",
    "        \"$UŠ\",\n",
    "        \"$KID\",\n",
    "        \"$DI\",\n",
    "        \"$GA₂\",\n",
    "        \"$HAR\",\n",
    "    ]:\n",
    "        row[KEY] = row[KEY].replace(str_, MISSING)\n",
    "    if \"$\" in row[KEY]:\n",
    "        print(f\"!!! Uncaught $ in {row['id']}\")\n",
    "    return row\n",
    "\n",
    "\n",
    "def _ellipses(row: pd.Series) -> pd.Series:\n",
    "    row[KEY] = row[KEY].replace(\"...\", MISSING)\n",
    "    return row\n",
    "\n",
    "\n",
    "def _standalone_parens(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    'The enclosed graphemes may be present but this is not certain;\n",
    "    normally used within [...] as in [x (x) x].'\n",
    "\n",
    "    https://oracc.museum.upenn.edu/doc/help/editinginatf/primer/inlinetutorial/index.html\n",
    "    \"\"\"\n",
    "    matches = re.findall(r\"(?:^|\\n|\\ |\\-)(\\([^\\n\\)]+\\))(?:$|\\n|\\ |\\-)\", row[KEY])\n",
    "    for match in matches:\n",
    "        print(\">> \", match, f\" ({row['id']})\")\n",
    "        row[KEY] = row[KEY].replace(match, \"\")\n",
    "    return row\n",
    "\n",
    "\n",
    "DISALLOWED_3 = [\"[\", \"]\", \"$\", \"...\"]\n",
    "\n",
    "\n",
    "def _sanity_check_3(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"Characters that should not be present at this point\"\"\"\n",
    "    for char in DISALLOWED_3:\n",
    "        if char in row[KEY]:\n",
    "            print(f\"!!! Disallowed character {char} in: {row['id']}\")\n",
    "    return row\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ---------------------------- enclosures ----------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "def _missing_alone_in_enclosure(row: pd.Series) -> pd.Series:\n",
    "    patterns = [\n",
    "        # Alone in parens\n",
    "        r\"(\\(\" + r\"[\\ \\-]*\" + MISSING + r\"[\\ \\-]*\" + r\"\\))\",\n",
    "        # Alone in brackets\n",
    "        r\"(\\{\" + r\"[\\ \\-]*\" + MISSING + r\"[\\ \\-]*\" + r\"\\})\",\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        row[KEY] = re.sub(\n",
    "            pattern,\n",
    "            MISSING,\n",
    "            row[KEY],\n",
    "        )\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def _empty_enclosures(row: pd.Series) -> pd.Series:\n",
    "    row[KEY] = row[KEY].replace(\"{}\", \"\")\n",
    "    row[KEY] = row[KEY].replace(\"()\", \"\")\n",
    "    return row\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ---------------------------- final cleanup -------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "DISALLOWED_FINAL = (\n",
    "    DISALLOWED_1\n",
    "    + DISALLOWED_2\n",
    "    + DISALLOWED_3\n",
    "    + [\" {MISSING}\", f\"{MISSING} \", \"\\n \", \" \\n\", \"  \"]\n",
    ")\n",
    "\n",
    "\n",
    "def _sanity_check_final(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"Check for characters that should not be present at this point.\"\"\"\n",
    "    for char in DISALLOWED_FINAL:\n",
    "        if char in row[KEY]:\n",
    "            print(f\"Disallowed character {char} in: {row['id']}\")\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def _convert_special_tokens(row: pd.Series) -> pd.Series:\n",
    "    text = row[KEY]\n",
    "    text = text.replace(\n",
    "        SpecialTokensBefore.MISSING.value, SpecialTokensAfter.MISSING.value\n",
    "    )\n",
    "    text = text.replace(\n",
    "        SpecialTokensBefore.SURFACE.value, SpecialTokensAfter.SURFACE.value\n",
    "    )\n",
    "    text = text.replace(\n",
    "        SpecialTokensBefore.COLUMN.value, SpecialTokensAfter.COLUMN.value\n",
    "    )\n",
    "    text = text.replace(\n",
    "        SpecialTokensBefore.BLANK_SPACE.value, SpecialTokensAfter.BLANK_SPACE.value\n",
    "    )\n",
    "    text = text.replace(\n",
    "        SpecialTokensBefore.RULING.value, SpecialTokensAfter.RULING.value\n",
    "    )\n",
    "    text = text.replace(\n",
    "        SpecialTokensBefore.NEWLINE.value, SpecialTokensAfter.NEWLINE.value\n",
    "    )\n",
    "\n",
    "    row[KEY] = text\n",
    "    return row\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _remove_tablets_with_no_transliteration(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Filter out tablets where transliteration without special tokens is empty\n",
    "    print(\n",
    "        \"Filtering out tablets with empty transliterations (beside special tokens)...\"\n",
    "    )\n",
    "    print(f\"Initial number of tablets: {len(df)}\")\n",
    "\n",
    "    special_tokens = [token.value for token in SpecialTokensAfter]\n",
    "\n",
    "    def _without_special_tokens(x: str) -> str:\n",
    "        for token in special_tokens:\n",
    "            x = x.replace(token, \"\")\n",
    "        return x\n",
    "\n",
    "    df = df[df[KEY].apply(_without_special_tokens) != \"\"]\n",
    "    print(f\"Updated number of tablets: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
